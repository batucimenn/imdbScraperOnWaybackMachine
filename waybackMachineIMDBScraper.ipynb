{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB Scraper from Wayback Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filmID input Ex: tt0120338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filmId= input(\"filmID: \")\n",
    "film='https://www.imdb.com/title/'+filmId\n",
    "filePath = input(\"File path: \"+\"r'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filePath+\"/\"+filmId+\".csv\", mode='w', newline='') as newFolder:\n",
    "    newWriter = csv.writer(newFolder, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL) \n",
    "    newWriter.writerow(['Year'+\";\"+'Month'+\";\"+'Day'+\";\"+'Hours'+\";\"+'Rating'+\";\"+'Toplam Oy'])\n",
    "    newFolder.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime='20070228'\n",
    "finishTime='20070331'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://web.archive.org/cdx/search/cdx?url='+film+'/&collapse=digest&from='+startTime+'&to='+finishTime+'&output=json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = rq.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_url = json.loads(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "for i in range(1,len(parse_url)):\n",
    "    orig_url = parse_url[i][2]\n",
    "    tstamp = parse_url[i][1]\n",
    "    waylink = 'https://web.archive.org/web/'+tstamp+'/'+orig_url\n",
    "    url_list.append(waylink)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(url_list)):\n",
    "    try:\n",
    "        final_url=url_list[i]\n",
    "        req = rq.get(final_url).text\n",
    "        print(req)\n",
    "        break\n",
    "        soup = bs(req,'html.parser')\n",
    "        classScraper = soup.find(class_='rating')\n",
    "        tagScraper1 = classScraper.find_all('b')\n",
    "        tagScraper2 = classScraper.find_all('a')\n",
    "        print(final_url[28:42]+\";\"+tagScraper1[1].contents[0].replace('/10','')+\";\"+tagScraper2[2].contents[0].replace('votes','').replace(',',''))\n",
    "        with open(filePath+\"/\"+filmId+\".csv\", mode='a', newline='') as newFolder:\n",
    "            newWriter = csv.writer(newFolder, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL) \n",
    "            newWriter.writerow([final_url[28:32]+\";\"+final_url[32:34]+\";\"+final_url[34:36]+\";\"+(final_url[36:38]+\":\"+final_url[38:40])+\";\"+tagScraper1[1].contents[0].replace('/10','')+\";\"+tagScraper2[2].contents[0].replace('votes','').replace(',','')])\n",
    "            newFolder.close()\n",
    "    except: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime='20070401'\n",
    "finishTime='20080531'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://web.archive.org/cdx/search/cdx?url='+film+'/&collapse=digest&from='+startTime+'&to='+finishTime+'&output=json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = rq.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_url = json.loads(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "for i in range(1,len(parse_url)):\n",
    "    orig_url = parse_url[i][2]\n",
    "    tstamp = parse_url[i][1]\n",
    "    waylink = 'https://web.archive.org/web/'+tstamp+'/'+orig_url\n",
    "    url_list.append(waylink)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(url_list)):\n",
    "    try:\n",
    "        final_url=url_list[i]\n",
    "        req = rq.get(final_url).text\n",
    "        soup = bs(req,'html.parser')\n",
    "        classScraper = soup.find(class_='general rating')\n",
    "        tagScraper1 = classScraper.find_all('b')\n",
    "        tagScraper2 = classScraper.find_all('a')\n",
    "        print(final_url[28:42]+\";\"+tagScraper1[1].contents[0].replace('/10','')+\";\"+tagScraper2[0].contents[0].replace('votes','').replace(',',''))\n",
    "        with open(filePath+\"/\"+filmId+\".csv\", mode='a', newline='') as newFolder:\n",
    "            newWriter = csv.writer(newFolder, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL) \n",
    "            newWriter.writerow([final_url[28:32]+\";\"+final_url[32:34]+\";\"+final_url[34:36]+\";\"+(final_url[36:38]+\":\"+final_url[38:40])+\";\"+tagScraper1[1].contents[0].replace('/10','')+\";\"+tagScraper2[0].contents[0].replace('votes','').replace(',','')])\n",
    "            newFolder.close()\n",
    "    except: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime='20080601'\n",
    "finishTime='20091231'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://web.archive.org/cdx/search/cdx?url='+film+'/&collapse=digest&from='+startTime+'&to='+finishTime+'&output=json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = rq.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_url = json.loads(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "for i in range(1,len(parse_url)):\n",
    "    orig_url = parse_url[i][2]\n",
    "    tstamp = parse_url[i][1]\n",
    "    waylink = 'https://web.archive.org/web/'+tstamp+'/'+orig_url\n",
    "    url_list.append(waylink)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(url_list)):\n",
    "    try:\n",
    "        final_url=url_list[i]\n",
    "        req = rq.get(final_url).text\n",
    "        soup = bs(req,'html.parser')\n",
    "        classScraper = soup.find(class_='meta')\n",
    "        tagScraper1 = classScraper.find_all('b')\n",
    "        tagScraper2 = classScraper.find_all('a')\n",
    "        print(final_url[28:42]+\";\"+tagScraper1[0].contents[0].replace('/10','')+\";\"+tagScraper2[0].contents[0].replace('votes','').replace(',',''))\n",
    "        with open(filePath+\"/\"+filmId+\".csv\", mode='a', newline='') as newFolder:\n",
    "            newWriter = csv.writer(newFolder, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL) \n",
    "            newWriter.writerow([final_url[28:32]+\";\"+final_url[32:34]+\";\"+final_url[34:36]+\";\"+(final_url[36:38]+\":\"+final_url[38:40])+\";\"+tagScraper1[0].contents[0].replace('/10','')+\";\"+tagScraper2[0].contents[0].replace('votes','').replace(',','')])\n",
    "            newFolder.close()\n",
    "    except: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime='20100101'\n",
    "finishTime='20100930'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://web.archive.org/cdx/search/cdx?url='+film+'/&collapse=digest&from='+startTime+'&to='+finishTime+'&output=json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = rq.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_url = json.loads(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "for i in range(1,len(parse_url)):\n",
    "    orig_url = parse_url[i][2]\n",
    "    tstamp = parse_url[i][1]\n",
    "    waylink = 'https://web.archive.org/web/'+tstamp+'/'+orig_url\n",
    "    url_list.append(waylink)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(url_list)):\n",
    "    try:\n",
    "        final_url=url_list[i]\n",
    "        req = rq.get(final_url).text\n",
    "        soup = bs(req,'html.parser')\n",
    "        classScraper = soup.find(class_='starbar-meta')\n",
    "        tagScraper1 = classScraper.find_all('b')\n",
    "        tagScraper2 = classScraper.find_all('a')\n",
    "        print(final_url[28:42]+\";\"+tagScraper1[0].contents[0].replace('/10','')+\";\"+tagScraper2[0].contents[0].replace('votes','').replace(',',''))\n",
    "        with open(filePath+\"/\"+filmId+\".csv\", mode='a', newline='') as newFolder:\n",
    "            newWriter = csv.writer(newFolder, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL) \n",
    "            newWriter.writerow([final_url[28:32]+\";\"+final_url[32:34]+\";\"+final_url[34:36]+\";\"+(final_url[36:38]+\":\"+final_url[38:40])+\";\"+tagScraper1[0].contents[0].replace('/10','')+\";\"+tagScraper2[0].contents[0].replace('votes','').replace(',','')])\n",
    "            newFolder.close()\n",
    "    except: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime='20101001'\n",
    "finishTime='20110731'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://web.archive.org/cdx/search/cdx?url='+film+'/&collapse=digest&from='+startTime+'&to='+finishTime+'&output=json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = rq.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_url = json.loads(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "for i in range(1,len(parse_url)):\n",
    "    orig_url = parse_url[i][2]\n",
    "    tstamp = parse_url[i][1]\n",
    "    waylink = 'https://web.archive.org/web/'+tstamp+'/'+orig_url\n",
    "    url_list.append(waylink)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(url_list)):\n",
    "    try:\n",
    "        final_url=url_list[i]\n",
    "        req = rq.get(final_url).text\n",
    "        soup = bs(req,'html.parser')\n",
    "        classScraper = soup.find(class_='star-box')\n",
    "        tagScraper1 = classScraper.find_all('a')\n",
    "        tagScraper2 = classScraper.find_all('span')\n",
    "        print(final_url[28:42]+\";\"+tagScraper2[13].contents[0]+\";\"+tagScraper1[11].contents[0].replace(',','').replace('votes',''))\n",
    "        with open(filePath+\"/\"+filmId+\".csv\", mode='a', newline='') as newFolder:\n",
    "            newWriter = csv.writer(newFolder, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL) \n",
    "            newWriter.writerow([final_url[28:32]+\";\"+final_url[32:34]+\";\"+final_url[34:36]+\";\"+(final_url[36:38]+\":\"+final_url[38:40])+\";\"+tagScraper2[13].contents[0]+\";\"+tagScraper1[11].contents[0].replace(',','').replace('votes','')])\n",
    "            newFolder.close()\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime='20110801'\n",
    "finishTime='20151213'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://web.archive.org/cdx/search/cdx?url='+film+'/&collapse=digest&from='+startTime+'&to='+finishTime+'&output=json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = rq.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_url = json.loads(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "for i in range(1,len(parse_url)):\n",
    "    orig_url = parse_url[i][2]\n",
    "    tstamp = parse_url[i][1]\n",
    "    waylink = 'https://web.archive.org/web/'+tstamp+'/'+orig_url\n",
    "    url_list.append(waylink)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(url_list)):\n",
    "    try:\n",
    "        final_url=url_list[i]\n",
    "        req = rq.get(final_url).text\n",
    "        soup = bs(req,'html.parser')\n",
    "        classScraper = soup.find(class_='star-box-details')\n",
    "        tagScraper1 = classScraper.find_all('span')\n",
    "        print(final_url[28:42]+\";\"+tagScraper1[0].contents[0]+\";\"+tagScraper1[3].contents[0].replace(',',''))\n",
    "        with open(filePath+\"/\"+filmId+\".csv\", mode='a', newline='') as newFolder:\n",
    "            newWriter = csv.writer(newFolder, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL) \n",
    "            newWriter.writerow([final_url[28:32]+\";\"+final_url[32:34]+\";\"+final_url[34:36]+\";\"+(final_url[36:38]+\":\"+final_url[38:40])+\";\"+tagScraper1[0].contents[0]+\";\"+tagScraper1[3].contents[0].replace(',','')])\n",
    "            newFolder.close()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime='20151214'\n",
    "finishTime='20160106'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://web.archive.org/cdx/search/cdx?url='+film+'/&collapse=digest&from='+startTime+'&to='+finishTime+'&output=json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = rq.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_url = json.loads(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "for i in range(1,len(parse_url)):\n",
    "    orig_url = parse_url[i][2]\n",
    "    tstamp = parse_url[i][1]\n",
    "    waylink = 'https://web.archive.org/web/'+tstamp+'/'+orig_url\n",
    "    url_list.append(waylink)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(url_list)):\n",
    "    try:\n",
    "        final_url=url_list[i]\n",
    "        req = rq.get(final_url).text\n",
    "        soup = bs(req,'html.parser')\n",
    "        classScraper = soup.find(class_='imdbRating')\n",
    "        tagScraper1 = classScraper.find_all('span')\n",
    "        print(final_url[28:42]+\";\"+tagScraper1[0].contents[0]+\";\"+tagScraper1[3].contents[0].replace(',',''))\n",
    "        with open(filePath+\"/\"+filmId+\".csv\", mode='a', newline='') as newFolder:\n",
    "            newWriter = csv.writer(newFolder, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL) \n",
    "            newWriter.writerow([final_url[28:32]+\";\"+final_url[32:34]+\";\"+final_url[34:36]+\";\"+(final_url[36:38]+\":\"+final_url[38:40])+\";\"+tagScraper1[0].contents[0]+\";\"+tagScraper1[3].contents[0].replace(',','')])\n",
    "            newFolder.close()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime='20160107'\n",
    "finishTime='20160126'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://web.archive.org/cdx/search/cdx?url='+film+'/&collapse=digest&from='+startTime+'&to='+finishTime+'&output=json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = rq.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_url = json.loads(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "for i in range(1,len(parse_url)):\n",
    "    orig_url = parse_url[i][2]\n",
    "    tstamp = parse_url[i][1]\n",
    "    waylink = 'https://web.archive.org/web/'+tstamp+'/'+orig_url\n",
    "    url_list.append(waylink)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(url_list)):\n",
    "    try:\n",
    "        final_url=url_list[i]\n",
    "        req = rq.get(final_url).text\n",
    "        soup = bs(req,'html.parser')\n",
    "        classScraper = soup.find(class_='star-box-details')\n",
    "        tagScraper1 = classScraper.find_all('span')\n",
    "        print(final_url[28:42]+\";\"+tagScraper1[0].contents[0]+\";\"+tagScraper1[3].contents[0].replace(',',''))\n",
    "        with open(filePath+\"/\"+filmId+\".csv\", mode='a', newline='') as newFolder:\n",
    "            newWriter = csv.writer(newFolder, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL) \n",
    "            newWriter.writerow([final_url[28:32]+\";\"+final_url[32:34]+\";\"+final_url[34:36]+\";\"+(final_url[36:38]+\":\"+final_url[38:40])+\";\"+tagScraper1[0].contents[0]+\";\"+tagScraper1[3].contents[0].replace(',','')])\n",
    "            newFolder.close()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime='20160127'\n",
    "finishTime='2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://web.archive.org/cdx/search/cdx?url='+film+'/&collapse=digest&from='+startTime+'&to='+finishTime+'&output=json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = rq.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_url = json.loads(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "for i in range(1,len(parse_url)):\n",
    "    orig_url = parse_url[i][2]\n",
    "    tstamp = parse_url[i][1]\n",
    "    waylink = 'https://web.archive.org/web/'+tstamp+'/'+orig_url\n",
    "    url_list.append(waylink)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(url_list)):\n",
    "    try:\n",
    "        final_url=url_list[i]\n",
    "        req = rq.get(final_url).text\n",
    "        soup = bs(req,'html.parser')\n",
    "        classScraper = soup.find(class_='imdbRating')\n",
    "        tagScraper1 = classScraper.find_all('span')\n",
    "        print(final_url[28:42]+\";\"+tagScraper1[0].contents[0]+\";\"+tagScraper1[3].contents[0].replace(',',''))\n",
    "        with open(filePath+\"/\"+filmId+\".csv\", mode='a', newline='') as newFolder:\n",
    "            newWriter = csv.writer(newFolder, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL) \n",
    "            newWriter.writerow([final_url[28:32]+\";\"+final_url[32:34]+\";\"+final_url[34:36]+\";\"+(final_url[36:38]+\":\"+final_url[38:40])+\";\"+tagScraper1[0].contents[0]+\";\"+tagScraper1[3].contents[0].replace(',','')])\n",
    "            newFolder.close()\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
